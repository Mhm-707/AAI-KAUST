{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699624992342,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"BCpQaqwoH2Pk"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":21591,"status":"ok","timestamp":1699625013930,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"HBuuF9MJKjoe"},"outputs":[],"source":["# Download the required libraries (needed when running outside colab where the environment doesn't come pre-loaded with libraries)\n","\n","%pip install torch\n","%pip install torchvision\n","%pip install matplotlib\n","\n","clear_output()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2387,"status":"ok","timestamp":1699625016315,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"gtV7omCIKq0K"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","from torchvision.datasets import CIFAR10\n","from torchvision.transforms.functional import to_tensor, to_pil_image, resize\n","\n","from torch.utils.data import DataLoader\n","from torch.optim import Adam\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"JBNjc2JpLGIa"},"source":["#Contents:\n","\n","1. We'll make a classifier for CIFAR10 dataset in pytorch using CNN architecture\n","\n","About CIFAR10:\n","\n","The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n","\n","![CIFAR-10 image](https://production-media.paperswithcode.com/datasets/4fdf2b82-2bc3-4f97-ba51-400322b228b1.png)\n","\n","\n","You need to know:\n","\n","1. **torch** (for impelementation)\n","2. a little bit of **matplotlib** (for visualization)\n","\n","\n","Good to have knowledge of:\n","\n","1. torch dataset and dataloader"]},{"cell_type":"markdown","metadata":{"id":"Gw5z1ZSoLlh1"},"source":["# Downloading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1830,"status":"ok","timestamp":1699625018142,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"MlJwrK5ZLDeV","outputId":"a15d3b45-fe73-4718-9fa6-6392ed027974"},"outputs":[],"source":["dataset_root = 'data/'\n","\n","train_dataset = CIFAR10(root=dataset_root, train=True, download=True, transform=to_tensor)\n","# Todo: Create a validation dataset\n","..."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699625018142,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"60ugrf0DMF2N","outputId":"312a489b-f541-4a13-fe3f-5e0b7c7c7f2f"},"outputs":[],"source":["print('Length of train_dataset is', len(train_dataset))\n","# Todo: Print the length of the validation dataset\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699625018142,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"Oj4XUGKBQmwH"},"outputs":[],"source":["batch_size = 64\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","# Todo: Create a validation data loader\n"]},{"cell_type":"markdown","metadata":{"id":"4bw5HNZeQ7Gc"},"source":["## Let's visualize the images and it's channels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699625018142,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"kXxCJ5pQQ5jw","outputId":"93fcc481-80cf-436b-d3b2-8deb63747847"},"outputs":[],"source":["random_img_idx = torch.randint(0, 1000, (1,)).item()\n","\n","test_image = train_dataset[random_img_idx][0]  # 0 for image part in (image, label) tuple.\n","test_image = resize(test_image, (250, 250), antialias=None)  # better visualization\n","print(test_image.shape)\n","print('Number of channels in test_image: ', test_image.shape[0])\n","to_pil_image(test_image)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699625018142,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"4RH33qBjR6IC"},"outputs":[],"source":["tred, tgreen, tblue = test_image\n","empty_channel = torch.zeros_like(tred)\n","\n","tred = [tred, empty_channel, empty_channel]  #R00\n","tgreen = [empty_channel, tgreen, empty_channel]  #0G0\n","tblue = [empty_channel, empty_channel, tblue]  #00B\n","\n","channels = [torch.stack(img) for img in [tred, tgreen, tblue]]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"executionInfo":{"elapsed":976,"status":"ok","timestamp":1699625019114,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"oKUDr6rTTl9K","outputId":"cf383db4-760a-481c-a5fe-457795da4d41"},"outputs":[],"source":["to_pil_image(torch.cat(channels, dim=2))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699625019114,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"qsgP23s4QNib"},"outputs":[],"source":["class Cifar10Classifier(nn.Module):\n","\n","  def __init__(self):\n","\n","    super(Cifar10Classifier, self).__init__()\n","    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","\n","    self.relu = nn.ReLU()  # Relu isn't learnable. no need to intialize different relu objects for each layer\n","    self.pool = nn.MaxPool2d(2, 2)  # pool isn't learnable to no need to initialize different pool layers unless we want to change window size\n","\n","    self.fc1 = nn.Linear(128 * 4 * 4, 512)\n","    self.fc2 = nn.Linear(512, 10)\n","\n","    self.softmax = nn.Softmax(dim=-1)\n","\n","  def forward(self, x: torch.Tensor):\n","\n","    single_input = False\n","    if x.ndim == 3:  # 3 dimensions mean [C, H, W] instead of [B, C, H, W] so we're dealing with a single image\n","      x = x.unsqueeze(dim=0)  # convert [C, H, W] to [1, C, H, W] where 1 will act as batch size\n","\n","      # keep track of whether input was one (non-batch) image.\n","      # If so, we want to convert it back to the same format after inference for consistency purposes\n","      single_input = True\n","\n","    # TODO: Implement the forward pass for the model\n","\n","    if single_input:\n","      x = x.squeeze(dim=0)  # or x = x[0]\n","\n","    return x\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1476,"status":"ok","timestamp":1699625020588,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"Vg_ZO5lNZ5B-"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'  # checks if machine supports cuda and if it does, we use that, otherwise cpu\n","model = Cifar10Classifier().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699625020588,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"E5wBeaz7Zdar","outputId":"8a7514b5-2a0a-4569-8e2c-f133b5c07adf"},"outputs":[],"source":["# TODO: Set the number of epochs\n","num_epochs = ...\n","# TODO: Set the learning rate\n","lr = ... \n","\n","train_losses = []\n","val_losses = []\n","\n","# TODO: Set the optimizer and the loss function\n","optimizer = ...\n","criterion = ...\n","\n","model.to(device)  # we need to send all input tensors as well as our model to this device. by default they are on cpu\n","\n","print(f'Using device {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":372032,"status":"ok","timestamp":1699625392618,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"mVZ6QIbIZb0A","outputId":"5adb82b1-52a9-4805-a7f4-920dca835600"},"outputs":[],"source":["%%time\n","for epoch_no in range(num_epochs):\n","\n","  # TODO: Set the model to train mode and iterate through the training data\n","  ... \n","\n","  epoch_weighted_loss = 0\n","\n","  for batch_X, batch_y in train_loader:\n","\n","    batch_X = batch_X.to(device)\n","    batch_y = batch_y.to(device)\n","\n","    # TODO: Perform the forward pass and get the predictions\n","    batch_y_probs = ...  # outputs [N, 10] where each [:, 10] is probabilities for class (0-9)\n","    # TODO: Calculate the loss using the predictions and the actual labels\n","    loss = ...\n","\n","    # TODO: Perform the backward pass and update the weights\n","    ...\n","\n","    epoch_weighted_loss += (len(batch_y)*loss.item())\n","\n","  epoch_loss = epoch_weighted_loss/len(train_loader.dataset)\n","  train_losses.append(epoch_loss)\n","\n","\n","  # validation time\n","\n","  # TODO: Set the model to evaluation mode and iterate through the validation data\n","  ...\n","  correctly_labelled = 0\n","\n","  with torch.no_grad():\n","\n","    val_epoch_weighted_loss = 0\n","\n","    for val_batch_X, val_batch_y in val_loader:\n","\n","      val_batch_X = val_batch_X.to(device)\n","      val_batch_y = val_batch_y.to(device)\n","      # TODO: Perform the forward pass and get the predictions\n","      val_batch_y_probs = ... \n","      # TODO: Calculate the loss using the predictions and the actual labels\n","      loss = ... \n","      val_epoch_weighted_loss += (len(val_batch_y)*loss.item())\n","\n","      val_batch_y_pred = val_batch_y_probs.argmax(dim=1)  # convert probailities to labels by picking the label (index) with the highest prob\n","\n","      correctly_labelled += (val_batch_y_pred == val_batch_y).sum().item()  # item converts tensor to float/int/list\n","\n","  val_epoch_loss = val_epoch_weighted_loss/len(val_loader.dataset)\n","  val_losses.append(val_epoch_loss)\n","\n","  print(f'Epoch: {epoch_no}, train_loss={epoch_loss}, val_loss={val_epoch_loss}. labelled {correctly_labelled}/{len(val_loader.dataset)} correctly ({correctly_labelled/len(val_loader.dataset)*100}% accuracy)')\n","\n","print(f'Training complete on device {device}.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1699625392619,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"2cMN5vKga0Fk","outputId":"eaf45caa-fede-4aee-8251-fce54803a8de"},"outputs":[],"source":["plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses  , label='Val Loss')\n","\n","plt.ylabel('Loss (CCE)')\n","plt.xlabel('Epoch')\n","\n","plt.legend()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOQG0TCXOQMpleeyT89R+iD","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}
